<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Wine Data Analysis &mdash; SciArts.org</title>
  <meta name="author" content="Mangs">

  <link rel="canonical" href="/wine.html"/>
  
  <meta property="og:site_name" content="SciArts.org" />
  <meta property="og:type" content="article" />
    
  <meta property="og:title" content="Wine Data Analysis" />
  <meta property="og:url" content="/wine.html" />
  <meta property="og:description" content="To analyze the information given in the 'Wines' dataset. Classify the wines based on their place of origin. This data contains the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines." />
  <meta property="article:published_time" content="2018-05-27 10:20:00-07:00" />
  <meta property="article:modified_time" content="2018-05-27 10:20:00-07:00" />






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
</head>

<body >
  <header role="banner"
  >
<hgroup>
  <h1><a href="/">SciArts.org</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
    <li><a href="/archives.html">Archives</a></li>
    <li><a href="/pages/about.html">About</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Wine Data Analysis</h1>
    <p class="meta">
<time datetime="2018-05-27T10:20:00-07:00" pubdate>Sun 27 May 2018</time>      
    </p>
</header>

    <div class="entry-content"><p>To analyze the information given in the 'Wines' dataset. Classify the wines based on their place of origin. This data contains the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. </p>
<p>I found the <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data">data</a> from a study which measured chemical constituents like alcohol, malic acid and various other constituents.</p>
<p>For this analysis, I'm going to use logistic regression, decision tree, random forest, naive bayes model , SVM and GBM from the dataset and compare the classification accuracy. Later I will use grid search approach to identify best model tuning parameters and compare the model performance</p>
<p>First we'll start by importing some packages and then import the data. </p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">sklearn.ensemble</span> <span class="k">as</span> <span class="nn">ske</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="c1">#from IPython.display import Image</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">log_loss</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">itemgetter</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="n">labelencoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
</pre></div>


<p>We'll display a snapshot of the data.</p>
<div class="highlight"><pre><span></span><span class="n">wine_data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span><span class="s1">&#39;Malicacid&#39;</span><span class="p">,</span><span class="s1">&#39;Ash&#39;</span><span class="p">,</span><span class="s1">&#39;Alcalinityofash&#39;</span><span class="p">,</span><span class="s1">&#39;Magnesium&#39;</span><span class="p">,</span><span class="s1">&#39;Totalphenols&#39;</span><span class="p">,</span><span class="s1">&#39;Flavanoids&#39;</span>
                     <span class="p">,</span><span class="s1">&#39;Nonflavanoidphenols&#39;</span><span class="p">,</span> <span class="s1">&#39;Proanth&#39;</span><span class="p">,</span><span class="s1">&#39;Colorintensity&#39;</span><span class="p">,</span><span class="s1">&#39;Hue&#39;</span><span class="p">,</span><span class="s1">&#39;OD280&#39;</span><span class="p">,</span><span class="s1">&#39;Proline&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">wine_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>


<div class="highlight"><pre><span></span>   <span class="k">Class</span>  <span class="n">Alcohol</span>  <span class="n">Malicacid</span>   <span class="n">Ash</span>  <span class="n">Alcalinityofash</span>  <span class="n">Magnesium</span>  <span class="n">Totalphenols</span>  <span class="err">\</span>
<span class="mi">0</span>      <span class="mi">1</span>    <span class="mi">13</span><span class="p">.</span><span class="mi">20</span>       <span class="mi">1</span><span class="p">.</span><span class="mi">78</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">14</span>             <span class="mi">11</span><span class="p">.</span><span class="mi">2</span>        <span class="mi">100</span>          <span class="mi">2</span><span class="p">.</span><span class="mi">65</span>   
<span class="mi">1</span>      <span class="mi">1</span>    <span class="mi">13</span><span class="p">.</span><span class="mi">16</span>       <span class="mi">2</span><span class="p">.</span><span class="mi">36</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">67</span>             <span class="mi">18</span><span class="p">.</span><span class="mi">6</span>        <span class="mi">101</span>          <span class="mi">2</span><span class="p">.</span><span class="mi">80</span>   
<span class="mi">2</span>      <span class="mi">1</span>    <span class="mi">14</span><span class="p">.</span><span class="mi">37</span>       <span class="mi">1</span><span class="p">.</span><span class="mi">95</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">50</span>             <span class="mi">16</span><span class="p">.</span><span class="mi">8</span>        <span class="mi">113</span>          <span class="mi">3</span><span class="p">.</span><span class="mi">85</span>   
<span class="mi">3</span>      <span class="mi">1</span>    <span class="mi">13</span><span class="p">.</span><span class="mi">24</span>       <span class="mi">2</span><span class="p">.</span><span class="mi">59</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">87</span>             <span class="mi">21</span><span class="p">.</span><span class="mi">0</span>        <span class="mi">118</span>          <span class="mi">2</span><span class="p">.</span><span class="mi">80</span>   
<span class="mi">4</span>      <span class="mi">1</span>    <span class="mi">14</span><span class="p">.</span><span class="mi">20</span>       <span class="mi">1</span><span class="p">.</span><span class="mi">76</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">45</span>             <span class="mi">15</span><span class="p">.</span><span class="mi">2</span>        <span class="mi">112</span>          <span class="mi">3</span><span class="p">.</span><span class="mi">27</span>

   <span class="n">Flavanoids</span>  <span class="n">Nonflavanoidphenols</span>  <span class="n">Proanth</span>  <span class="n">Colorintensity</span>   <span class="n">Hue</span>  <span class="n">OD280</span>  <span class="err">\</span>
<span class="mi">0</span>        <span class="mi">2</span><span class="p">.</span><span class="mi">76</span>                 <span class="mi">0</span><span class="p">.</span><span class="mi">26</span>     <span class="mi">1</span><span class="p">.</span><span class="mi">28</span>            <span class="mi">4</span><span class="p">.</span><span class="mi">38</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">05</span>   <span class="mi">3</span><span class="p">.</span><span class="mi">40</span>   
<span class="mi">1</span>        <span class="mi">3</span><span class="p">.</span><span class="mi">24</span>                 <span class="mi">0</span><span class="p">.</span><span class="mi">30</span>     <span class="mi">2</span><span class="p">.</span><span class="mi">81</span>            <span class="mi">5</span><span class="p">.</span><span class="mi">68</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">03</span>   <span class="mi">3</span><span class="p">.</span><span class="mi">17</span>   
<span class="mi">2</span>        <span class="mi">3</span><span class="p">.</span><span class="mi">49</span>                 <span class="mi">0</span><span class="p">.</span><span class="mi">24</span>     <span class="mi">2</span><span class="p">.</span><span class="mi">18</span>            <span class="mi">7</span><span class="p">.</span><span class="mi">80</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">86</span>   <span class="mi">3</span><span class="p">.</span><span class="mi">45</span>   
<span class="mi">3</span>        <span class="mi">2</span><span class="p">.</span><span class="mi">69</span>                 <span class="mi">0</span><span class="p">.</span><span class="mi">39</span>     <span class="mi">1</span><span class="p">.</span><span class="mi">82</span>            <span class="mi">4</span><span class="p">.</span><span class="mi">32</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">04</span>   <span class="mi">2</span><span class="p">.</span><span class="mi">93</span>   
<span class="mi">4</span>        <span class="mi">3</span><span class="p">.</span><span class="mi">39</span>                 <span class="mi">0</span><span class="p">.</span><span class="mi">34</span>     <span class="mi">1</span><span class="p">.</span><span class="mi">97</span>            <span class="mi">6</span><span class="p">.</span><span class="mi">75</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">05</span>   <span class="mi">2</span><span class="p">.</span><span class="mi">85</span>

   <span class="n">Proline</span>  
<span class="mi">0</span>     <span class="mi">1050</span>  
<span class="mi">1</span>     <span class="mi">1185</span>  
<span class="mi">2</span>     <span class="mi">1480</span>  
<span class="mi">3</span>      <span class="mi">735</span>  
<span class="mi">4</span>     <span class="mi">1450</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">wine_data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">labelencoder</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df_labelencoded</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">labelencoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_labelencoded</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>


<div class="highlight"><pre><span></span>   <span class="k">Class</span>  <span class="n">Alcohol</span>  <span class="n">Malicacid</span>  <span class="n">Ash</span>  <span class="n">Alcalinityofash</span>  <span class="n">Magnesium</span>  <span class="n">Totalphenols</span>  <span class="err">\</span>
<span class="mi">0</span>      <span class="mi">0</span>       <span class="mi">65</span>         <span class="mi">49</span>   <span class="mi">18</span>                <span class="mi">1</span>         <span class="mi">21</span>            <span class="mi">68</span>   
<span class="mi">1</span>      <span class="mi">0</span>       <span class="mi">63</span>         <span class="mi">71</span>   <span class="mi">62</span>               <span class="mi">31</span>         <span class="mi">22</span>            <span class="mi">73</span>   
<span class="mi">2</span>      <span class="mi">0</span>      <span class="mi">120</span>         <span class="mi">59</span>   <span class="mi">48</span>               <span class="mi">20</span>         <span class="mi">33</span>            <span class="mi">95</span>   
<span class="mi">3</span>      <span class="mi">0</span>       <span class="mi">67</span>         <span class="mi">81</span>   <span class="mi">74</span>               <span class="mi">44</span>         <span class="mi">37</span>            <span class="mi">73</span>   
<span class="mi">4</span>      <span class="mi">0</span>      <span class="mi">115</span>         <span class="mi">47</span>   <span class="mi">45</span>               <span class="mi">10</span>         <span class="mi">32</span>            <span class="mi">89</span>

   <span class="n">Flavanoids</span>  <span class="n">Nonflavanoidphenols</span>  <span class="n">Proanth</span>  <span class="n">Colorintensity</span>  <span class="n">Hue</span>  <span class="n">OD280</span>  <span class="err">\</span>
<span class="mi">0</span>          <span class="mi">91</span>                    <span class="mi">9</span>       <span class="mi">31</span>              <span class="mi">56</span>   <span class="mi">50</span>    <span class="mi">102</span>   
<span class="mi">1</span>         <span class="mi">114</span>                   <span class="mi">13</span>       <span class="mi">96</span>              <span class="mi">82</span>   <span class="mi">48</span>     <span class="mi">86</span>   
<span class="mi">2</span>         <span class="mi">121</span>                    <span class="mi">7</span>       <span class="mi">84</span>             <span class="mi">108</span>   <span class="mi">30</span>    <span class="mi">104</span>   
<span class="mi">3</span>          <span class="mi">89</span>                   <span class="mi">20</span>       <span class="mi">66</span>              <span class="mi">53</span>   <span class="mi">49</span>     <span class="mi">73</span>   
<span class="mi">4</span>         <span class="mi">119</span>                   <span class="mi">17</span>       <span class="mi">75</span>              <span class="mi">96</span>   <span class="mi">50</span>     <span class="mi">68</span>

   <span class="n">Proline</span>  
<span class="mi">0</span>       <span class="mi">92</span>  
<span class="mi">1</span>      <span class="mi">101</span>  
<span class="mi">2</span>      <span class="mi">116</span>  
<span class="mi">3</span>       <span class="mi">66</span>  
<span class="mi">4</span>      <span class="mi">115</span>
</pre></div>


<p>We'll make some plots to see the data available to us.</p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">18</span>

<span class="n">wine_data</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span><span class="s1">&#39;Malicacid&#39;</span><span class="p">,</span><span class="s1">&#39;Ash&#39;</span><span class="p">,</span><span class="s1">&#39;Alcalinityofash&#39;</span><span class="p">],</span>
            <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E1E75B70&gt;,</span>
<span class="err">        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E2131940&gt;],</span>
<span class="err">       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E21581D0&gt;,</span>
<span class="err">        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E2173240&gt;]], dtype=object)</span>
</pre></div>


<p><img alt="png" src="/images/wine_8_1.png"></p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">11</span>
<span class="n">wine_data</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E24A09B0&gt;,</span>
<span class="err">       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E22BDA90&gt;,</span>
<span class="err">       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000C6E22E1940&gt;], dtype=object)</span>
</pre></div>


<p><img alt="png" src="/images/wine_9_1.png"></p>
<div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span><span class="s1">&#39;Ash&#39;</span><span class="p">,</span><span class="n">wine_data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">&lt;seaborn.axisgrid.FacetGrid at 0xc6e2481da0&gt;</span>
</pre></div>


<p><img alt="png" src="/images/wine_10_1.png"></p>
<div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span><span class="s1">&#39;Ash&#39;</span><span class="p">,</span><span class="n">wine_data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">fit_reg</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">&lt;seaborn.axisgrid.FacetGrid at 0xc6e27dceb8&gt;</span>
</pre></div>


<p><img alt="png" src="/images/wine_11_1.png"></p>
<div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;Alcohol&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">wine_data</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">&lt;matplotlib.axes._subplots.AxesSubplot at 0xc6e266d4a8&gt;</span>
</pre></div>


<p><img alt="png" src="/images/wine_12_1.png"></p>
<div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">13</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------y values------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">----------y values------------</span>
<span class="err">[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span>
<span class="err"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span>
<span class="err"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span>
<span class="err"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3</span>
<span class="err"> 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]</span>
</pre></div>


<p>Here we'll split the data into a training set and a testing set.</p>
<div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Feature Scaling</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">model_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;Accuracy Score&#39;</span><span class="p">,</span><span class="s1">&#39;Log loss&#39;</span><span class="p">]</span>
<span class="n">model_log</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">model_cols</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Applying PCA</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------Applying PCA-------------&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">explained_variance</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------Explained Variance------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">explained_variance</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------Covariance------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">get_covariance</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------Precision------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">get_precision</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="o">-------------</span><span class="n">Applying</span> <span class="n">PCA</span><span class="o">-------------</span>
<span class="o">------------</span><span class="n">Explained</span> <span class="n">Variance</span><span class="o">------------</span>
<span class="p">[</span> <span class="mf">0.37362934</span>  <span class="mf">0.18399859</span><span class="p">]</span>
<span class="o">------------</span><span class="n">Covariance</span><span class="o">------------</span>
<span class="o">&lt;</span><span class="n">bound</span> <span class="n">method</span> <span class="n">_BasePCA</span><span class="o">.</span><span class="n">get_covariance</span> <span class="n">of</span> <span class="n">PCA</span><span class="p">(</span><span class="n">copy</span><span class="o">=</span><span class="n">True</span><span class="p">,</span> <span class="n">iterated_power</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>
  <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="n">False</span><span class="p">)</span><span class="o">&gt;</span>
<span class="o">------------</span><span class="n">Precision</span><span class="o">------------</span>
<span class="o">&lt;</span><span class="n">bound</span> <span class="n">method</span> <span class="n">_BasePCA</span><span class="o">.</span><span class="n">get_precision</span> <span class="n">of</span> <span class="n">PCA</span><span class="p">(</span><span class="n">copy</span><span class="o">=</span><span class="n">True</span><span class="p">,</span> <span class="n">iterated_power</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>
  <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="n">False</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">model_log_entry</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="s1">&#39;PCA &#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">model_cols</span><span class="p">)</span>
<span class="n">model_log_entry</span>
<span class="n">model_log</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_log_entry</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Fitting Logistic Regression to the Training set</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predicting the Test set results</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Making the Confusion Matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------Confusion Matrix------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------accuracy score-------------&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="n">acs</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="n">model_log_entry</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="s1">&#39;Logistic Regression &#39;</span><span class="p">,</span> 
                                 <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
                                 <span class="s2">&quot;&quot;</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">model_cols</span><span class="p">)</span>
<span class="n">model_log</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_log_entry</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">-------------Confusion Matrix------------</span>
<span class="err">[[12  2  0]</span>
<span class="err"> [ 0 14  1]</span>
<span class="err"> [ 0  0  7]]</span>
<span class="err">-----------accuracy score-------------</span>
<span class="err">0.916666666667</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Visualising the Training set results</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
              <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">((</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X1</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X2</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
     <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                 <span class="n">c</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">((</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Logistic Regression (Training set)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_20_0.png"></p>
<div class="highlight"><pre><span></span><span class="c1"># Visualising the Test set results</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">X_set</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">X2</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
             <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">((</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X1</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X2</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_set</span><span class="p">)):</span>
     <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_set</span><span class="p">[</span><span class="n">y_set</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                 <span class="n">c</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">((</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">))(</span><span class="n">i</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">j</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Logistic Regression (Test set)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_21_0.png"></p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------Applying Decision Tree------------&quot;</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">dtree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">dtree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">dtree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cmDT</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Decision Tree confusion matrix and accuracy score&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmDT</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
<span class="n">model_log_entry</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="s1">&#39;Decision Tree &#39;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">),</span><span class="s1">&#39;&#39;</span><span class="p">]],</span> <span class="n">columns</span><span class="o">=</span><span class="n">model_cols</span><span class="p">)</span>
<span class="n">model_log</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_log_entry</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">-------------Applying Decision Tree------------</span>
<span class="err">Decision Tree confusion matrix and accuracy score</span>
<span class="err">[[14  0  0]</span>
<span class="err"> [ 1 12  2]</span>
<span class="err"> [ 0  0  7]]</span>
<span class="err">0.916666666667</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">dtree</span><span class="p">,</span> <span class="n">out_file</span> <span class="o">=</span> <span class="s1">&#39;wine1_dtree22.dot&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">popen</span><span class="p">(</span><span class="s1">&#39;dot &quot;wine1_dtree22.dot&quot; -Tpng -o &quot;wine1_dtree22.png&quot;&#39;</span><span class="p">)</span>
<span class="n">dtimg</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;wine1_dtree22.png&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dtimg</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">&lt;matplotlib.image.AxesImage at 0xc6e3e616d8&gt;</span>
</pre></div>


<p><img alt="png" src="/images/wine_24_1.png"></p>
<p>Next, we'll go through different classifiers and list the Accuracy and Log Loss for each classifier.</p>
<div class="highlight"><pre><span></span><span class="c1">#log for visual comparison</span>
<span class="n">log_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Log Loss&quot;</span><span class="p">]</span>
<span class="n">basic_log</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">log_cols</span><span class="p">)</span>
<span class="n">best_model_log</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">log_cols</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1">#Initializing classifiers with default</span>
<span class="n">basic_classifiers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">KNeighborsClassifier</span><span class="p">(),</span>
    <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">DecisionTreeClassifier</span><span class="p">(),</span>
    <span class="n">AdaBoostClassifier</span><span class="p">(),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(),</span>
    <span class="n">GradientBoostingClassifier</span><span class="p">(),</span>
    <span class="n">GaussianNB</span><span class="p">()]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1">#print classifiers</span>
<span class="n">basic_classifiers</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">[KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,</span>
<span class="err">            metric_params=None, n_jobs=1, n_neighbors=5, p=2,</span>
<span class="err">            weights=&#39;uniform&#39;),</span>
<span class="err"> SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span>
<span class="err">   decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,</span>
<span class="err">   max_iter=-1, probability=True, random_state=None, shrinking=True,</span>
<span class="err">   tol=0.001, verbose=False),</span>
<span class="err"> LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,</span>
<span class="err">           intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,</span>
<span class="err">           penalty=&#39;l2&#39;, random_state=0, solver=&#39;liblinear&#39;, tol=0.0001,</span>
<span class="err">           verbose=0, warm_start=False),</span>
<span class="err"> DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,</span>
<span class="err">             max_features=None, max_leaf_nodes=None,</span>
<span class="err">             min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">             min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">             min_weight_fraction_leaf=0.0, presort=False, random_state=None,</span>
<span class="err">             splitter=&#39;best&#39;),</span>
<span class="err"> AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;, base_estimator=None,</span>
<span class="err">           learning_rate=1.0, n_estimators=50, random_state=None),</span>
<span class="err"> RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,</span>
<span class="err">             max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,</span>
<span class="err">             min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">             min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,</span>
<span class="err">             oob_score=False, random_state=None, verbose=0,</span>
<span class="err">             warm_start=False),</span>
<span class="err"> GradientBoostingClassifier(criterion=&#39;friedman_mse&#39;, init=None,</span>
<span class="err">               learning_rate=0.1, loss=&#39;deviance&#39;, max_depth=3,</span>
<span class="err">               max_features=None, max_leaf_nodes=None,</span>
<span class="err">               min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">               min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">               min_weight_fraction_leaf=0.0, n_estimators=100,</span>
<span class="err">               presort=&#39;auto&#39;, random_state=None, subsample=1.0, verbose=0,</span>
<span class="err">               warm_start=False),</span>
<span class="err"> GaussianNB(priors=None)]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Printing results from base classifier&quot;</span><span class="p">)</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">basic_classifiers</span><span class="p">:</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;****Results****&#39;</span><span class="p">)</span>
    <span class="n">train_predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">train_predictions</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">{:.4%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

    <span class="n">train_predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">train_predictions</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Log Loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ll</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Printing results from base classifier</span>
<span class="err">==============================</span>
<span class="err">KNeighborsClassifier</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 83.3333%</span>
<span class="err">Log Loss: 2.19159634006964</span>
<span class="err">==============================</span>
<span class="err">SVC</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 86.1111%</span>
<span class="err">Log Loss: 0.30756417482227505</span>
<span class="err">==============================</span>
<span class="err">LogisticRegression</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 91.6667%</span>
<span class="err">Log Loss: 0.24735412308073323</span>
<span class="err">==============================</span>
<span class="err">DecisionTreeClassifier</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 91.6667%</span>
<span class="err">Log Loss: 2.878231366242558</span>
<span class="err">==============================</span>
<span class="err">AdaBoostClassifier</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 86.1111%</span>
<span class="err">Log Loss: 0.6466171620181561</span>
<span class="err">==============================</span>
<span class="err">RandomForestClassifier</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 97.2222%</span>
<span class="err">Log Loss: 0.18896288822511523</span>
<span class="err">==============================</span>
<span class="err">GradientBoostingClassifier</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 91.6667%</span>
<span class="err">Log Loss: 0.11083595399697523</span>
<span class="err">==============================</span>
<span class="err">GaussianNB</span>
<span class="err">****Results****</span>
<span class="c">Accuracy: 91.6667%</span>
<span class="err">Log Loss: 0.08836397292012357</span>
<span class="err">==============================</span>
</pre></div>


<p>I will run a grid search for each of the classifiers and display the best hyper parameters for each classifier.</p>
<div class="highlight"><pre><span></span><span class="c1">#best model classifiers using variables</span>
<span class="n">best_model_classifiers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gs_knn_classifier</span><span class="p">,</span>
    <span class="n">gs_svm_classifier</span><span class="p">,</span>
    <span class="n">gs_logreg_classifier</span><span class="p">,</span>
    <span class="n">gs_dtree_classifier</span><span class="p">,</span>
    <span class="n">gs_ab_classifier</span><span class="p">,</span>
    <span class="n">gs_rf_classifier</span><span class="p">,</span>
    <span class="n">gs_gb_classifier</span><span class="p">,</span>
    <span class="n">gs_gnb_classifier</span>
<span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">best_model_classifiers</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">[KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,</span>
<span class="err">            metric_params=None, n_jobs=1, n_neighbors=3, p=2,</span>
<span class="err">            weights=&#39;uniform&#39;),</span>
<span class="err"> SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span>
<span class="err">   decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;linear&#39;,</span>
<span class="err">   max_iter=-1, probability=True, random_state=None, shrinking=True,</span>
<span class="err">   tol=0.001, verbose=False),</span>
<span class="err"> LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,</span>
<span class="err">           intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,</span>
<span class="err">           penalty=&#39;l2&#39;, random_state=0, solver=&#39;liblinear&#39;, tol=0.0001,</span>
<span class="err">           verbose=0, warm_start=False),</span>
<span class="err"> DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=5,</span>
<span class="err">             max_features=None, max_leaf_nodes=None,</span>
<span class="err">             min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">             min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">             min_weight_fraction_leaf=0.0, presort=False, random_state=None,</span>
<span class="err">             splitter=&#39;best&#39;),</span>
<span class="err"> AdaBoostClassifier(algorithm=&#39;SAMME&#39;, base_estimator=None, learning_rate=1.0,</span>
<span class="err">           n_estimators=100, random_state=None),</span>
<span class="err"> RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,</span>
<span class="err">             max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,</span>
<span class="err">             min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">             min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">             min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,</span>
<span class="err">             oob_score=False, random_state=None, verbose=0,</span>
<span class="err">             warm_start=False),</span>
<span class="err"> GradientBoostingClassifier(criterion=&#39;friedman_mse&#39;, init=None,</span>
<span class="err">               learning_rate=0.1, loss=&#39;deviance&#39;, max_depth=3,</span>
<span class="err">               max_features=None, max_leaf_nodes=None,</span>
<span class="err">               min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="err">               min_samples_leaf=1, min_samples_split=2,</span>
<span class="err">               min_weight_fraction_leaf=0.0, n_estimators=100,</span>
<span class="err">               presort=&#39;auto&#39;, random_state=None, subsample=1.0, verbose=0,</span>
<span class="err">               warm_start=False),</span>
<span class="err"> GaussianNB(priors=None)]</span>
</pre></div>


<p>Printing results using best hyper parameters from grid search using variables.</p>
<div class="highlight"><pre><span></span><span class="n">Printing</span> <span class="n">results</span> <span class="n">using</span> <span class="n">best</span> <span class="n">hyper</span> <span class="n">parameters</span> <span class="n">from</span> <span class="n">grid</span> <span class="n">search</span> <span class="n">using</span> <span class="n">variables</span>
<span class="o">==============================</span>
<span class="n">KNeighborsClassifier</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">80.5556</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.1164576295998505</span>
<span class="o">==============================</span>
<span class="n">SVC</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">94.4444</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.15336951382205888</span>
<span class="o">==============================</span>
<span class="n">LogisticRegression</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.6667</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.24735412308073323</span>
<span class="o">==============================</span>
<span class="n">DecisionTreeClassifier</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.6667</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.878231366242558</span>
<span class="o">==============================</span>
<span class="n">AdaBoostClassifier</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.6667</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0006315027859083</span>
<span class="o">==============================</span>
<span class="n">RandomForestClassifier</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">97.2222</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.12975238096954453</span>
<span class="o">==============================</span>
<span class="n">GradientBoostingClassifier</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.6667</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1172436075713107</span>
<span class="o">==============================</span>
<span class="n">GaussianNB</span>
<span class="o">****</span><span class="n">Results</span><span class="o">****</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.6667</span><span class="o">%</span>
<span class="n">Log</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.08836397292012357</span>
<span class="o">==============================</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------Individual run----------------&quot;</span><span class="p">)</span>
<span class="n">model_log</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">------------------Individual run----------------</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy Score</th>
      <th>Log loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>PCA</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>Logistic Regression</td>
      <td>0.916667</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>Decision Tree</td>
      <td>0.916667</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------Base Classifiers--------------&quot;</span><span class="p">)</span>
<span class="n">basic_log</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">-----------Base Classifiers--------------</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Classifier</th>
      <th>Accuracy</th>
      <th>Log Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>KNeighborsClassifier</td>
      <td>83.333333</td>
      <td>2.191596</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVC</td>
      <td>86.111111</td>
      <td>0.307564</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LogisticRegression</td>
      <td>91.666667</td>
      <td>0.247354</td>
    </tr>
    <tr>
      <th>3</th>
      <td>DecisionTreeClassifier</td>
      <td>91.666667</td>
      <td>2.878231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AdaBoostClassifier</td>
      <td>86.111111</td>
      <td>0.646617</td>
    </tr>
    <tr>
      <th>5</th>
      <td>RandomForestClassifier</td>
      <td>97.222222</td>
      <td>0.188963</td>
    </tr>
    <tr>
      <th>6</th>
      <td>GradientBoostingClassifier</td>
      <td>91.666667</td>
      <td>0.110836</td>
    </tr>
    <tr>
      <th>7</th>
      <td>GaussianNB</td>
      <td>91.666667</td>
      <td>0.088364</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_color_codes</span><span class="p">(</span><span class="s2">&quot;muted&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">basic_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Accuracy %&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Classifier Accuracy&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_51_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_color_codes</span><span class="p">(</span><span class="s2">&quot;muted&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Log Loss&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">basic_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Log Loss %&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Classifier Log Loss&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_52_0.png"></p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----best model taken into variables for grid search-----&quot;</span><span class="p">)</span>
<span class="n">best_model_log</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="o">----</span><span class="n">best</span> <span class="n">model</span> <span class="n">taken</span> <span class="n">into</span> <span class="n">variables</span> <span class="k">for</span> <span class="n">grid</span> <span class="n">search</span><span class="o">-----</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Classifier</th>
      <th>Accuracy</th>
      <th>Log Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>KNeighborsClassifier</td>
      <td>80.555556</td>
      <td>2.116458</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVC</td>
      <td>94.444444</td>
      <td>0.153370</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LogisticRegression</td>
      <td>91.666667</td>
      <td>0.247354</td>
    </tr>
    <tr>
      <th>3</th>
      <td>DecisionTreeClassifier</td>
      <td>91.666667</td>
      <td>2.878231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AdaBoostClassifier</td>
      <td>91.666667</td>
      <td>1.000632</td>
    </tr>
    <tr>
      <th>5</th>
      <td>RandomForestClassifier</td>
      <td>97.222222</td>
      <td>0.129752</td>
    </tr>
    <tr>
      <th>6</th>
      <td>GradientBoostingClassifier</td>
      <td>91.666667</td>
      <td>0.117244</td>
    </tr>
    <tr>
      <th>7</th>
      <td>GaussianNB</td>
      <td>91.666667</td>
      <td>0.088364</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_color_codes</span><span class="p">(</span><span class="s2">&quot;muted&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">best_model_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Accuracy %&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Classifier Accuracy from Grid Search&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_54_0.png"></p>
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">font</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_color_codes</span><span class="p">(</span><span class="s2">&quot;muted&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Log Loss&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">best_model_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Log Loss %&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Classifier Accuracy&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="/images/wine_55_0.png"></p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Basic classifiers </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">basic_log</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Best model classifiers using grid search </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model_log</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Basic</span> <span class="n">classifiers</span>

                   <span class="n">Classifier</span>   <span class="n">Accuracy</span>  <span class="n">Log</span> <span class="n">Loss</span>
<span class="mi">0</span>        <span class="n">KNeighborsClassifier</span>  <span class="mi">83</span><span class="p">.</span><span class="mi">333333</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">191596</span>
<span class="mi">0</span>                         <span class="n">SVC</span>  <span class="mi">86</span><span class="p">.</span><span class="mi">111111</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">307564</span>
<span class="mi">0</span>          <span class="n">LogisticRegression</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">247354</span>
<span class="mi">0</span>      <span class="n">DecisionTreeClassifier</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">878231</span>
<span class="mi">0</span>          <span class="n">AdaBoostClassifier</span>  <span class="mi">86</span><span class="p">.</span><span class="mi">111111</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">646617</span>
<span class="mi">0</span>      <span class="n">RandomForestClassifier</span>  <span class="mi">97</span><span class="p">.</span><span class="mi">222222</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">188963</span>
<span class="mi">0</span>  <span class="n">GradientBoostingClassifier</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">110836</span>
<span class="mi">0</span>                  <span class="n">GaussianNB</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">088364</span>

 <span class="n">Best</span> <span class="n">model</span> <span class="n">classifiers</span> <span class="k">using</span> <span class="n">grid</span> <span class="k">search</span>

                   <span class="n">Classifier</span>   <span class="n">Accuracy</span>  <span class="n">Log</span> <span class="n">Loss</span>
<span class="mi">0</span>        <span class="n">KNeighborsClassifier</span>  <span class="mi">80</span><span class="p">.</span><span class="mi">555556</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">116458</span>
<span class="mi">0</span>                         <span class="n">SVC</span>  <span class="mi">94</span><span class="p">.</span><span class="mi">444444</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">153370</span>
<span class="mi">0</span>          <span class="n">LogisticRegression</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">247354</span>
<span class="mi">0</span>      <span class="n">DecisionTreeClassifier</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">878231</span>
<span class="mi">0</span>          <span class="n">AdaBoostClassifier</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">000632</span>
<span class="mi">0</span>      <span class="n">RandomForestClassifier</span>  <span class="mi">97</span><span class="p">.</span><span class="mi">222222</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">129752</span>
<span class="mi">0</span>  <span class="n">GradientBoostingClassifier</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">117244</span>
<span class="mi">0</span>                  <span class="n">GaussianNB</span>  <span class="mi">91</span><span class="p">.</span><span class="mi">666667</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">088364</span>
</pre></div></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Mangs
    </span>
  </span>
<time datetime="2018-05-27T10:20:00-07:00" pubdate>Sun 27 May 2018</time>  <span class="categories">
    <a class='category' href='/category/misc.html'>misc</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">Python</a>,    <a class="category" href="/tag/data-science.html">Data Science</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>

<aside class="sidebar">
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    <li class="post">
        <a href="/reuters.html">Reuters Newswire Topics Classification</a>
    </li>
    <li class="post">
        <a href="/cifar.html">Image Classification</a>
    </li>
    <li class="post">
        <a href="/airpsg.html">Airline Passengers Data Analysis</a>
    </li>
    <li class="post">
        <a href="/wine.html">Wine Data Analysis</a>
    </li>
    <li class="post">
        <a href="/tableau.html">Tableau Dashboard</a>
    </li>
  </ul>
</section><section>
  <h1>Categories</h1>
    <ul id="recent_posts">
      <li><a href="/category/misc.html">misc (5)</a></li>
  </ul>
</section>
<section>
  <h1>Tags</h1>
    <a href="/tag/python.html">Python</a>,    <a href="/tag/data-science.html">Data Science</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/tableau.html">Tableau</a></section>

</aside>
    </div>
  </div>
  <footer role="contentinfo">
<p>
    Copyright &copy;  2017&ndash;2020  Mangs &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p>  </footer>
</body>
</html>